import argparse
import json
import logging
import os
import re
import shutil
import zipfile
from collections import namedtuple

import requests

import set_log
from downloader import artifactory_dict


class Downloader:
    """
        Main class that operates the download process:
        1. enables logs
        2. parses arguments to get settings file
        3. loads JSON to named tuple
        4. gets URL for selected version based on server
        5. downloads zip archive with BETA build
        """
    def __init__(self):
        self.settings_path = None
        self.build_url = None
        self.zip_file = None
        self.product_info_new = None

        set_log.set_logger()

        self.parse_args()
        if not self.settings_path:
            return

        with open(self.settings_path, "r") as file:
            self.settings = json.load(file, object_hook=lambda d: namedtuple('X', d.keys())(*d.values()))

        self.get_build_link()

        if not self.build_url:
            logging.error("Cannot receive URL")
            return

        self.download_file(self.build_url)

        if not self.zip_file:
            logging.error("ZIP download failed")
            return

        self.install()

    def parse_args(self):
        """
        Function to parse arguments provided to the script. Search for -p key to get settings path
        :return: settings_path: path to the configuration file
        """
        parser = argparse.ArgumentParser()
        # Add long and short argument
        parser.add_argument("--path", "-p", help="set path to the settings file generated by UI")
        args = parser.parse_args()

        if args.path:
            self.settings_path = args.path
            if not os.path.isfile(self.settings_path):
                self.settings_path = None
                logging.error("Settings file does not exist")

            logging.info(f"Settings path is set to {self.settings_path}")

    def get_build_link(self):
        """
        Function that sends HTTP request to JFrog and get the list of folders with builds for EDT and checks user
        password
        :return: (str) url: URL link to the latest build that will be used to download .zip archive
        """
        if not self.settings.username or not self.settings.password:
            logging.error("Please provide username and artifactory password")
            return False

        server = artifactory_dict[self.settings.artifactory]
        try:
            with requests.get(server + "/api/repositories", auth=(self.settings.username, self.settings.password),
                              timeout=30) as url_request:
                artifacts_list = json.loads(url_request.text)
        except requests.exceptions.ReadTimeout:
            logging.error("Timeout on connection, please verify your username and password for {}".format(
                self.settings.artifactory))
            return False

        # catch 401 for bad credentials or similar
        if url_request.status_code != 200:
            if url_request.status_code == 401:
                logging.error("Bad credentials, please verify your username and password for {}".format(
                    self.settings.artifactory))
            else:
                logging.error(artifacts_list["errors"][0]["message"])
            return

        # fill the dictionary with EBU and WB keys since builds could be different
        # still parse the list because of different names on servers
        artifacts_dict = {}
        for artifact in artifacts_list:
            repo = artifact["key"]
            if "EBU_Certified" in repo:
                version = repo.split("_")[0] + "_EDT"
                if version not in artifacts_dict:
                    artifacts_dict[version] = repo
            elif "Certified" in repo and "Licensing" not in repo:
                version = repo.split("_")[0] + "_WB"
                if version not in artifacts_dict:
                    artifacts_dict[version] = repo

        repo = artifacts_dict[self.settings.version]

        if "EDT" in self.settings.version:
            url = server + "/api/storage/" + repo + "?list&deep=0&listFolders=1"
            with requests.get(url, auth=(self.settings.username, self.settings.password), timeout=30) as url_request:
                folder_dict_list = json.loads(url_request.text)['files']

            builds_dates = []
            for folder_dict in folder_dict_list:
                folder_name = folder_dict['uri'][1:]
                try:
                    builds_dates.append(int(folder_name))
                except ValueError:
                    pass

            latest_build = max(builds_dates)

            self.build_url = (f"{server}/{repo}/{latest_build}/Electronics_{self.settings.version.split('_')[0][1:]}" +
                              "_winx64.zip")
        elif "WB" in self.settings.version:
            self.build_url = f"{server}/api/archive/download/{repo}-cache/winx64?archiveType=zip"

    def download_file(self, url, recursion=False):
        """
        Downloads file in chunks and saves to the temp.zip file
        :param (str) url: to the zip archive or special JFrog API to download WB folder
        :param (bool) recursion: Some artifactories do not have cached folders with WB  and we need recursively run
        the same function but with new_url, however to prevent infinity loop we need this arg
        :return: (str) destination_file: link to the zip file
        """
        with requests.get(url, auth=(self.settings.username, self.settings.password),
                          timeout=30, stream=True) as url_request:
            if url_request.status_code == 404 and not recursion:
                # in HQ cached build does not exist and will return 404. Recursively start download with new url
                self.download_file(url.replace("-cache", ""), recursion=True)
                return False

            destination_file = os.path.join(self.settings.download_path, f"temp_build_{self.settings.version}.zip")
            logging.info(f"Start download file from {url} to {destination_file}")
            with open(destination_file, 'wb') as f:
                shutil.copyfileobj(url_request.raw, f)

            logging.info(f"File is downloaded to: {destination_file}")
            self.zip_file = destination_file

    def install(self):
        # todo check that the same version is already installed or not before deletion
        target_dir = self.zip_file.replace(".zip", "")
        with zipfile.ZipFile(self.zip_file, "r") as zip_ref:
            zip_ref.extractall(target_dir)

        logging.info(f"File is unpacked to {target_dir}")

        if "EDT" in self.settings.version:
            self.install_edt(target_dir)

    def install_edt(self, target_dir):
        product_id = self.parse_iss(target_dir)
        if product_id:
            logging.info(f"Product ID is {product_id}")
            if os.path.isfile(self.product_info_new):
                # file with build date exists and we can check version
                versions_different = self.compare_version()
            else:
                # file does not exist for some reason, need to install any case
                pass
        else:
            logging.error("Unable to extract product ID")
            return

    def uninstall(self):
        pass

    def compare_version(self):

        build_date, product_version = self.get_build_date(self.product_info_new)

        installed_product = os.path.join(self.settings.install_path, "AnsysEM", f"AnsysEM{product_version}",
                                         "Win64", "product.info")

        installed_build_date, _unused = self.get_build_date(installed_product)

        if all([build_date, installed_build_date]) and build_date == installed_build_date:
            return True
        return False

    @staticmethod
    def get_build_date(file_path):
        build_date = None
        product_version = None
        if os.path.isfile(file_path):
            with open(file_path) as file:
                for line in file:
                    if "AnsProductBuildDate" in line:
                        build_date = line.split("=")[1]
                    elif "AnsProductVersion" in line:
                        product_version = line.split("=")[1]

        return build_date, product_version


    def parse_iss(self, dir_name):
        default_iss_file = ""
        for dir_path, dir_names, file_names in os.walk(dir_name):
            for filename in file_names:
                if "AnsysEM" in dir_path and filename.endswith(".iss"):
                    default_iss_file = os.path.join(dir_path, filename)
                    self.product_info_new = os.path.join(dir_path, "product.info")
                    break

        if not default_iss_file:
            return False

        try:
            with open(default_iss_file, "r") as iss_file:
                for line in iss_file:
                    if "DlgOrder" in line:
                        product_id = re.findall("[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}", line)[0]
                        return product_id
        except IndexError:
            return False


if __name__ == "__main__":
    Downloader()
